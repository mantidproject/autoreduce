#!/usr/bin/env python
VERSION = "1.4.2"

from suds.client import Client

import nxs, os, numpy, sys, posixpath, glob, logging, time
import xml.utils.iso8601, ConfigParser
from datetime import datetime

def usage():
    print 'Usage: ingestAPSData <facilityName> <instrumentName> <investigationName> <runNumber> <plugin> <hostAndPort> <password>'
    print 'Example: ingestAPSData APS 11-ID-B PUP-1234 2013-2_ProffenJun13 db icat-testing.sns.gov:8181 password'
    sys.exit(-1)

def ingestData(facilityName, instrumentName, investigationName, runNumber, sessionId, service, factory):

    config = ConfigParser.RawConfigParser()
    config.read('aps.cfg')

    #directory = "/" + facilityName + "/" + instrumentName + "/" +  investigationName
    directory = "/SNS/users/3qr/data/" + facilityName + "/" + instrumentName + "/" +  investigationName
    print "proposal directory: " + directory
   
    config2 = ConfigParser.RawConfigParser()
    metaFile = directory + "/" + instrumentName + "_" + runNumber + "_metadata.cfg"
    config2.read(metaFile)
    print "metaFile: " + metaFile

    tifDir = directory + "/tif" 
    prefix = instrumentName + "_" + runNumber

    tifDSType = factory.create("datasetType")
    tifDSType.id = config.get('DatasetType', 'experiment_raw')

    dataset = factory.create("dataset")
    dataset.name = runNumber + "_tif"
    dataset.location = directory
    datafiles = []
       
    for dirpath, dirnames, filenames in os.walk(tifDir):
        for filename in [f for f in filenames]:
            if filename.startswith('.') != True and filename.startswith(prefix):
                datafile = factory.create("datafile")
                filepath = os.path.join(dirpath,filename)
                extension = os.path.splitext(filename)[1][1:]
                datafile.name = filename
                datafile.location = filepath
                dfFormat = factory.create("datafileFormat")
                dfFormat.id = config.get('DatafileFormat', extension)
                datafile.datafileFormat = dfFormat 
                '''modTime = os.path.getmtime(filepath)
                datafile.datafileCreateTime = xml.utils.iso8601.tostring(modTime)'''
                datafile.fileSize = os.path.getsize(filepath)
                addDatafileParameters(datafile, config, config2, factory)

                datafiles.append(datafile)
             
    dataset.datafiles = datafiles
    dataset.type = tifDSType
	    
    dbDatasets = service.search(sessionId, "Dataset INCLUDE Datafile [name = '" + str(dataset.name) + "'] <-> Investigation <-> Instrument [name = '" + instrumentName + "'] <-> DatasetType [name = 'experiment_raw']")

    if len(dbDatasets) == 0:
    
        dbInvestigations = service.search(sessionId, "Investigation [name = '" + str(investigationName) + "'] <-> Instrument [name = '" + instrumentName + "']")
       
        if len(dbInvestigations) == 0:
            investigation = factory.create("investigation")
            investigation.name = investigationName
            investigation.title = "Could we get investigation title from proposal db?" 

            #find facility, investigation_type 
            facility = factory.create("facility")
            facility.id = config.get('Facility', 'aps')
            investigation.facility = facility
            instrument = factory.create("instrument")
            instrument.id = config.get('Instrument', instrumentName)
            investigation.instrument = instrument 
            invType = factory.create("investigationType")
            invType.id = config.get('InvestigationType', 'experiment')
            investigation.type = invType

            logging.info("New IPTS: creating investigation...")
            # create new investigation
            invId = service.create(sessionId, investigation)
            investigation.id = invId

        elif len(dbInvestigations) == 1:
            investigation = dbInvestigations[0]

        else:
            print "ERROR, there should be only one investigation per instrument per investigation name"  
            return 1

        print "Creating dataset: ", str(datetime.now())
        dataset.investigation = investigation
        service.create(sessionId, dataset)
            
    elif len(dbDatasets) == 1:
    
        print "reduced dataset %s is already cataloged, updating reduced dataset..."%(dataset.name)
        
        dbDataset = dbDatasets[0]
        print "  dataset: %s"%(str(dbDataset.id))
        
        # update "one to many" relationships
        if hasattr(dbDataset, "datafiles"):
            dfs = getattr(dbDataset, "datafiles")
            service.deleteMany(sessionId, dfs)
            
        print "old datafiles are deleted"

        for df in datafiles:
            print df.name 
            df.dataset = dbDataset
        print "creating new  datafiles"
        service.createMany(sessionId, datafiles)
        
    else:
        print "ERROR, there should be only one dataset per run number per type reduced" 
    
    print "DATASET:"
    print "  RUN NUMBER: %s"%(str(dataset.name))
    print "  TITLE: %s"%(str(dataset.description))
    print "  START TIME: %s"%(str(dataset.startDate))
    print "  END TIME: %s"%(str(dataset.endDate))

    for datafile in dataset.datafiles:
        print "DATAFILE:"
        print "  NAME: %s"%(str(datafile.name))
        print "  LOCATION: %s"%(str(datafile.location))

    return 0

def addDatafileParameters(datafile, config, config2, factory):
    parameters = []
    paramTypes = ['width', 'height', 'exposureTime', 'summedExposures', 'imageNumber', 'phaseNumber', 'nPhases']

    for param in paramTypes:
        parameterType = factory.create("parameterType")
        parameterType.id = config.get('ParameterType', param)
        parameterType.applicableToDatafile = 1
        datafileParameter = factory.create("datafileParameter")
        datafileParameter.type = parameterType 
        datafileParameter.numericValue = config2.get(datafile.name, param) 
        parameters.append(datafileParameter)

    datafile.parameters = parameters

    dateString = config2.get(datafile.name, "dateString")
    formatedDate = datetime.strptime(dateString, '%Y.%m.%d : %H:%M:%S.%f')
    datafile.datafileCreateTime = xml.utils.iso8601.tostring(time.mktime(formatedDate.timetuple()))

def main(argv):
    args = sys.argv[1:]
    if len(args) != 7:
        usage()

    facilityName = args[0]
    instrumentName = args[1]
    investigationName = args[2]
    runNumber = args[3]
    plugin = args[4]
    hostAndPort = args[5]
    password = args[6]

    client = Client("https://" + hostAndPort + "/ICATService/ICAT?wsdl")
    service = client.service
    factory = client.factory

    credentials = factory.create("credentials")
    entry = factory.create("credentials.entry")
    entry.key = "username"
    entry.value = "root"
    credentials.entry.append(entry)
    entry = factory.create("credentials.entry")
    entry.key = "password"
    entry.value = password
    credentials.entry.append(entry)

    print "Begin login at: ", str(datetime.now()) 
    sessionId = service.login(plugin, credentials)
    print "End login at: ", str(datetime.now()) 

    print "Begin ingesting raw data at: ", str(datetime.now()) 
    status = ingestData(facilityName, instrumentName, investigationName, runNumber, sessionId, service, factory)
    print "End ingesting raw data at: ", str(datetime.now()) 

    print "Begin logout at: ", str(datetime.now()) 
    service.logout(sessionId)
    print "End logout at: ", str(datetime.now()) 

if __name__ == "__main__":
   main(sys.argv[1:])
